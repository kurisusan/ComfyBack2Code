
# This file is auto-generated by generate_nodes.py
# Do not edit this file directly.

from ..base_node import Node, InputSlots, OutputSlots, Slot, Model, Conditioning, Latent, Image, Vae, Clip
from typing import Dict, Any, List, Union

# Define input and output slot classes for TorchCompileModelHyVideo
class TorchCompileModelHyVideoInputs(InputSlots):
    model: Slot[Model]
    backend: Slot[str]
    fullgraph: Slot[bool]
    mode: Slot[str]
    dynamic: Slot[bool]
    dynamo_cache_size_limit: Slot[int]
    compile_single_blocks: Slot[bool]
    compile_double_blocks: Slot[bool]
    compile_txt_in: Slot[bool]
    compile_vector_in: Slot[bool]
    compile_final_layer: Slot[bool]
    def __init__(self, node: "Node"):
        self.model = Slot[Model](node, "model", 'MODEL')
        self.backend = Slot[str](node, "backend", ['inductor', 'cudagraphs'])
        self.fullgraph = Slot[bool](node, "fullgraph", 'BOOLEAN')
        self.mode = Slot[str](node, "mode", ['default', 'max-autotune', 'max-autotune-no-cudagraphs', 'reduce-overhead'])
        self.dynamic = Slot[bool](node, "dynamic", 'BOOLEAN')
        self.dynamo_cache_size_limit = Slot[int](node, "dynamo_cache_size_limit", 'INT')
        self.compile_single_blocks = Slot[bool](node, "compile_single_blocks", 'BOOLEAN')
        self.compile_double_blocks = Slot[bool](node, "compile_double_blocks", 'BOOLEAN')
        self.compile_txt_in = Slot[bool](node, "compile_txt_in", 'BOOLEAN')
        self.compile_vector_in = Slot[bool](node, "compile_vector_in", 'BOOLEAN')
        self.compile_final_layer = Slot[bool](node, "compile_final_layer", 'BOOLEAN')

class TorchCompileModelHyVideoOutputs(OutputSlots):
    model: Slot[Model]
    def __init__(self, node: "Node"):
        self.model = Slot[Model](node, "MODEL", 'MODEL')

class TorchCompileModelHyVideo(Node[TorchCompileModelHyVideoInputs, TorchCompileModelHyVideoOutputs]):
    """
    Original name: TorchCompileModelHyVideo
    Category: KJNodes/torchcompile
    

    Inputs:
        - model (Model)
        - backend (str) (default: 'inductor')
        - fullgraph (bool) (default: False)
          Enable full graph mode
        - mode (str) (default: 'default')
        - dynamic (bool) (default: False)
          Enable dynamic mode
        - dynamo_cache_size_limit (int) (default: 64)
          torch._dynamo.config.cache_size_limit
        - compile_single_blocks (bool) (default: True)
          Compile single blocks
        - compile_double_blocks (bool) (default: True)
          Compile double blocks
        - compile_txt_in (bool) (default: False)
          Compile txt_in layers
        - compile_vector_in (bool) (default: False)
          Compile vector_in layers
        - compile_final_layer (bool) (default: False)
          Compile final layer

    Outputs:
        - model (Model)
    """
    _original_name: str = 'TorchCompileModelHyVideo'

    def __init__(self, model: Slot[Model], backend: str = 'inductor', fullgraph: bool = False, mode: str = 'default', dynamic: bool = False, dynamo_cache_size_limit: int = 64, compile_single_blocks: bool = True, compile_double_blocks: bool = True, compile_txt_in: bool = False, compile_vector_in: bool = False, compile_final_layer: bool = False):
        super().__init__(**{"model": model, "backend": backend, "fullgraph": fullgraph, "mode": mode, "dynamic": dynamic, "dynamo_cache_size_limit": dynamo_cache_size_limit, "compile_single_blocks": compile_single_blocks, "compile_double_blocks": compile_double_blocks, "compile_txt_in": compile_txt_in, "compile_vector_in": compile_vector_in, "compile_final_layer": compile_final_layer})
        self.inputs = TorchCompileModelHyVideoInputs(self)
        self.outputs = TorchCompileModelHyVideoOutputs(self)
