
# This file is auto-generated by generate_nodes.py
# Do not edit this file directly.

from ..base_node import Node, InputSlots, OutputSlots, Slot, Model, Conditioning, Latent, Image, Vae, Clip
from typing import Dict, Any, List, Union

# Define input and output slot classes for VHS_BatchManager
class VHS_BatchManagerInputs(InputSlots):
    frames_per_batch: Slot[int]
    def __init__(self, node: "Node"):
        self.frames_per_batch = Slot[int](node, "frames_per_batch", 'INT')

class VHS_BatchManagerOutputs(OutputSlots):
    meta_batch: Slot[Any]
    def __init__(self, node: "Node"):
        self.meta_batch = Slot[Any](node, "meta_batch", 'VHS_BatchManager')

class VHS_BatchManager(Node[VHS_BatchManagerInputs, VHS_BatchManagerOutputs]):
    """
    Original name: VHS_BatchManager
    Category: Video Helper Suite ðŸŽ¥ðŸ…¥ðŸ…—ðŸ…¢
    Meta Batch Manager ðŸŽ¥ðŸ…¥ðŸ…—ðŸ…¢<div style="font-size: 0.8em"><div id=VHS_shortdesc>Split the processing of a very long video into sets of smaller Meta Batches</div></div><div style="font-size: 0.8em">The Meta Batch Manager allows for extremely long input videos to be processed when all other methods for fitting the content in RAM fail. It does not effect VRAM usage.</div><div style="font-size: 0.8em">It must be connected to at least one Input (a Load Video or Load Images) AND at least one Video Combine</div><div style="font-size: 0.8em"><img src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/7cb3fb7e-59d8-4cb2-a09f-9c6698de8b1f loading=lazy style="width: 0px; min-width: 100%"></div><div style="font-size: 0.8em">It functions by holding both the inputs and ouputs open between executions, and automatically requeue's the workflow until one of the inputs is unable to provide additional images.</div><div style="font-size: 0.8em">Because each sub execution only contains a subset of the total frames, each sub execution creates a hard window which temporal smoothing can not be applied across. This results in jumps in the output.</div><div style="font-size: 0.8em"><div vhs_title="Outputs" style="display: flex; font-size: 0.8em" class="VHS_collapse"><div style="color: #AAA; height: 1.5em;">[<span style="font-family: monospace">-</span>]</div><div style="width: 100%">Outputs: <div vhs_title="meta_batch" style="display: flex; font-size: 1em" class="VHS_collapse"><div style="color: #AAA; height: 1.5em;">[<span style="font-family: monospace">-</span>]</div><div style="width: 100%">meta_batch: Add all connected nodes to this Meta Batch</div></div></div></div><div vhs_title="Widgets" style="display: flex; font-size: 0.8em" class="VHS_collapse"><div style="color: #AAA; height: 1.5em;">[<span style="font-family: monospace">-</span>]</div><div style="width: 100%">Widgets: <div vhs_title="frames_per_batch" style="display: flex; font-size: 1em" class="VHS_collapse"><div style="color: #AAA; height: 1.5em;">[<span style="font-family: monospace">-</span>]</div><div style="width: 100%">frames_per_batch: How many frames to process for each sub execution. If loading as image, each frame will use about 50MB of RAM (not VRAM), and this can safely be set in the 100-1000 range, depending on available memory. When loading and combining from latent space (no blue image noodles exist), this value can be much higher, around the 2,000 to 20,000 range</div></div></div></div></div>

    Inputs:
        - frames_per_batch (int) (default: 16)

    Outputs:
        - meta_batch (Any)
    """
    _original_name: str = 'VHS_BatchManager'

    def __init__(self, frames_per_batch: int = 16):
        super().__init__(**{"frames_per_batch": frames_per_batch})
        self.inputs = VHS_BatchManagerInputs(self)
        self.outputs = VHS_BatchManagerOutputs(self)
