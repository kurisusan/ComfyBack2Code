
# This file is auto-generated by generate_nodes.py
# Do not edit this file directly.

from ..base_node import Node, InputSlots, OutputSlots, Slot, Model, Conditioning, Latent, Image, Vae, Clip
from typing import Dict, Any, List

# Define input and output slot classes for TrainLoraNode
class TrainLoraNodeInputs(InputSlots):
    model: Slot[Model]
    latents: Slot[Latent]
    positive: Slot[Conditioning]
    batch_size: Slot[int]
    steps: Slot[int]
    learning_rate: Slot[float]
    rank: Slot[int]
    optimizer: Slot[str]
    loss_function: Slot[str]
    seed: Slot[int]
    training_dtype: Slot[str]
    lora_dtype: Slot[str]
    existing_lora: Slot[str]
    def __init__(self, node: "Node"):
        self.model = Slot[Model](node, "model", 'MODEL')
        self.latents = Slot[Latent](node, "latents", 'LATENT')
        self.positive = Slot[Conditioning](node, "positive", 'CONDITIONING')
        self.batch_size = Slot[int](node, "batch_size", 'INT')
        self.steps = Slot[int](node, "steps", 'INT')
        self.learning_rate = Slot[float](node, "learning_rate", 'FLOAT')
        self.rank = Slot[int](node, "rank", 'INT')
        self.optimizer = Slot[str](node, "optimizer", ['AdamW', 'Adam', 'SGD', 'RMSprop'])
        self.loss_function = Slot[str](node, "loss_function", ['MSE', 'L1', 'Huber', 'SmoothL1'])
        self.seed = Slot[int](node, "seed", 'INT')
        self.training_dtype = Slot[str](node, "training_dtype", ['bf16', 'fp32'])
        self.lora_dtype = Slot[str](node, "lora_dtype", ['bf16', 'fp32'])
        self.existing_lora = Slot[str](node, "existing_lora", ['[None]'])

class TrainLoraNodeOutputs(OutputSlots):
    model_with_lora: Slot[Model]
    lora: Slot[Any]
    loss: Slot[Any]
    steps: Slot[int]
    def __init__(self, node: "Node"):
        self.model_with_lora = Slot[Model](node, "model_with_lora", 'MODEL')
        self.lora = Slot[Any](node, "lora", 'LORA_MODEL')
        self.loss = Slot[Any](node, "loss", 'LOSS_MAP')
        self.steps = Slot[int](node, "steps", 'INT')

class TrainLoraNode(Node[TrainLoraNodeInputs, TrainLoraNodeOutputs]):
    """
    Original name: TrainLoraNode
    No description available.
    """
    _original_name: str = 'TrainLoraNode'

    def __init__(self, model: Slot[Model], latents: Slot[Latent], positive: Slot[Conditioning], batch_size: int = 1, steps: int = 16, learning_rate: float = 0.0005, rank: int = 8, optimizer: str = 'AdamW', loss_function: str = 'MSE', seed: int = 0, training_dtype: str = 'bf16', lora_dtype: str = 'bf16', existing_lora: str = '[None]'):
        super().__init__(**{"model": model, "latents": latents, "positive": positive, "batch_size": batch_size, "steps": steps, "learning_rate": learning_rate, "rank": rank, "optimizer": optimizer, "loss_function": loss_function, "seed": seed, "training_dtype": training_dtype, "lora_dtype": lora_dtype, "existing_lora": existing_lora})
        self.inputs = TrainLoraNodeInputs(self)
        self.outputs = TrainLoraNodeOutputs(self)
