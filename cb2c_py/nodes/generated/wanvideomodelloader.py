
# This file is auto-generated by generate_nodes.py
# Do not edit this file directly.

from ..base_node import Node

class WanVideoModelLoader(Node):
    """
    Original name: WanVideoModelLoader
    No description available.
    """
    _inputs = {
    "model": [
        [
            "Wan2_1-VACE_module_14B_fp8_e4m3fn.safetensors",
            "Wan2_1_VACE_1_3B_preview_bf16.safetensors",
            "cosmos_predict2_2B_video2world_480p_16fps.safetensors",
            "omnigen2_fp16.safetensors",
            "svdq-fp4_r32-flux.1-kontext-dev.safetensors",
            "wan2.1_vace_1.3B_fp16.safetensors",
            "wan2.1_vace_14B_fp8_e4m3fn.safetensors"
        ],
        {
            "tooltip": "These models are loaded from the 'ComfyUI/models/diffusion_models' -folder"
        }
    ],
    "base_precision": [
        [
            "fp32",
            "bf16",
            "fp16",
            "fp16_fast"
        ],
        {
            "default": "bf16"
        }
    ],
    "quantization": [
        [
            "disabled",
            "fp8_e4m3fn",
            "fp8_e4m3fn_fast",
            "fp8_e5m2",
            "fp8_e4m3fn_fast_no_ffn"
        ],
        {
            "default": "disabled",
            "tooltip": "optional quantization method"
        }
    ],
    "load_device": [
        [
            "main_device",
            "offload_device"
        ],
        {
            "default": "main_device",
            "tooltip": "Initial device to load the model to, NOT recommended with the larger models unless you have 48GB+ VRAM"
        }
    ]
}
    _outputs = [
    "WANVIDEOMODEL"
]
    _original_name = "WanVideoModelLoader"

    def __init__(self, model, base_precision="bf16", quantization="disabled", load_device="main_device"):
        super().__init__(model=model, base_precision=base_precision, quantization=quantization, load_device=load_device)

    @classmethod
    def get_inputs(cls):
        return cls._inputs

    @classmethod
    def get_outputs(cls):
        return cls._outputs
