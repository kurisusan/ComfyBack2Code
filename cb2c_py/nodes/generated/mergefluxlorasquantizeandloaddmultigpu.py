
# This file is auto-generated by generate_nodes.py
# Do not edit this file directly.

from ..base_node import Node, InputSlots, OutputSlots, Slot, Model, Conditioning, Latent, Image, Vae, Clip
from typing import Dict, Any, List, Union

# Define input and output slot classes for MergeFluxLoRAsQuantizeAndLoaddMultiGPU
class MergeFluxLoRAsQuantizeAndLoaddMultiGPUInputs(InputSlots):
    unet_name: Slot[str]
    switch_1: Slot[str]
    lora_name_1: Slot[str]
    lora_weight_1: Slot[float]
    switch_2: Slot[str]
    lora_name_2: Slot[str]
    lora_weight_2: Slot[float]
    switch_3: Slot[str]
    lora_name_3: Slot[str]
    lora_weight_3: Slot[float]
    switch_4: Slot[str]
    lora_name_4: Slot[str]
    lora_weight_4: Slot[float]
    quantization: Slot[str]
    delete_final_gguf: Slot[bool]
    new_model_name: Slot[str]
    def __init__(self, node: "Node"):
        self.unet_name = Slot[str](node, "unet_name", [])
        self.switch_1 = Slot[str](node, "switch_1", ['Off', 'On'])
        self.lora_name_1 = Slot[str](node, "lora_name_1", ['None'])
        self.lora_weight_1 = Slot[float](node, "lora_weight_1", 'FLOAT')
        self.switch_2 = Slot[str](node, "switch_2", ['Off', 'On'])
        self.lora_name_2 = Slot[str](node, "lora_name_2", ['None'])
        self.lora_weight_2 = Slot[float](node, "lora_weight_2", 'FLOAT')
        self.switch_3 = Slot[str](node, "switch_3", ['Off', 'On'])
        self.lora_name_3 = Slot[str](node, "lora_name_3", ['None'])
        self.lora_weight_3 = Slot[float](node, "lora_weight_3", 'FLOAT')
        self.switch_4 = Slot[str](node, "switch_4", ['Off', 'On'])
        self.lora_name_4 = Slot[str](node, "lora_name_4", ['None'])
        self.lora_weight_4 = Slot[float](node, "lora_weight_4", 'FLOAT')
        self.quantization = Slot[str](node, "quantization", ['Q2_K', 'Q3_K_S', 'Q4_0', 'Q4_1', 'Q4_K_S', 'Q5_0', 'Q5_1', 'Q5_K_S', 'Q6_K', 'Q8_0', 'FP16'])
        self.delete_final_gguf = Slot[bool](node, "delete_final_gguf", 'BOOLEAN')
        self.new_model_name = Slot[str](node, "new_model_name", 'STRING')

class MergeFluxLoRAsQuantizeAndLoaddMultiGPUOutputs(OutputSlots):
    model: Slot[Model]
    def __init__(self, node: "Node"):
        self.model = Slot[Model](node, "MODEL", 'MODEL')

class MergeFluxLoRAsQuantizeAndLoaddMultiGPU(Node[MergeFluxLoRAsQuantizeAndLoaddMultiGPUInputs, MergeFluxLoRAsQuantizeAndLoaddMultiGPUOutputs]):
    """
    Original name: MergeFluxLoRAsQuantizeAndLoaddMultiGPU
    Category: multigpu
    

    Inputs:
        - unet_name (str)
        - switch_1 (str)
        - lora_name_1 (str)
        - lora_weight_1 (float) (default: 1.0)
        - switch_2 (str)
        - lora_name_2 (str)
        - lora_weight_2 (float) (default: 1.0)
        - switch_3 (str)
        - lora_name_3 (str)
        - lora_weight_3 (float) (default: 1.0)
        - switch_4 (str)
        - lora_name_4 (str)
        - lora_weight_4 (float) (default: 1.0)
        - quantization (str) (default: 'Q4_K_S')
        - delete_final_gguf (bool) (default: False)
        - new_model_name (str) (default: 'merged_model')

    Outputs:
        - model (Model)
    """
    _original_name: str = 'MergeFluxLoRAsQuantizeAndLoaddMultiGPU'

    def __init__(self, unet_name: str, switch_1: str, lora_name_1: str, switch_2: str, lora_name_2: str, switch_3: str, lora_name_3: str, switch_4: str, lora_name_4: str, lora_weight_1: float = 1.0, lora_weight_2: float = 1.0, lora_weight_3: float = 1.0, lora_weight_4: float = 1.0, quantization: str = 'Q4_K_S', delete_final_gguf: bool = False, new_model_name: str = 'merged_model'):
        super().__init__(**{"unet_name": unet_name, "switch_1": switch_1, "lora_name_1": lora_name_1, "lora_weight_1": lora_weight_1, "switch_2": switch_2, "lora_name_2": lora_name_2, "lora_weight_2": lora_weight_2, "switch_3": switch_3, "lora_name_3": lora_name_3, "lora_weight_3": lora_weight_3, "switch_4": switch_4, "lora_name_4": lora_name_4, "lora_weight_4": lora_weight_4, "quantization": quantization, "delete_final_gguf": delete_final_gguf, "new_model_name": new_model_name})
        self.inputs = MergeFluxLoRAsQuantizeAndLoaddMultiGPUInputs(self)
        self.outputs = MergeFluxLoRAsQuantizeAndLoaddMultiGPUOutputs(self)
