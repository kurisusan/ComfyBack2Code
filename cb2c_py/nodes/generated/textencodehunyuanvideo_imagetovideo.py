
# This file is auto-generated by generate_nodes.py
# Do not edit this file directly.

from ..base_node import Node, InputSlots, OutputSlots, Slot, Model, Conditioning, Latent, Image, Vae, Clip
from typing import Dict, Any, List

# Define input and output slot classes for TextEncodeHunyuanVideo_ImageToVideo
class TextEncodeHunyuanVideo_ImageToVideoInputs(InputSlots):
    clip: Slot[Clip]
    clip_vision_output: Slot[Any]
    prompt: Slot[str]
    image_interleave: Slot[int]
    def __init__(self, node: "Node"):
        self.clip = Slot[Clip](node, "clip", 'CLIP')
        self.clip_vision_output = Slot[Any](node, "clip_vision_output", 'CLIP_VISION_OUTPUT')
        self.prompt = Slot[str](node, "prompt", 'STRING')
        self.image_interleave = Slot[int](node, "image_interleave", 'INT')

class TextEncodeHunyuanVideo_ImageToVideoOutputs(OutputSlots):
    conditioning: Slot[Conditioning]
    def __init__(self, node: "Node"):
        self.conditioning = Slot[Conditioning](node, "CONDITIONING", 'CONDITIONING')

class TextEncodeHunyuanVideo_ImageToVideo(Node[TextEncodeHunyuanVideo_ImageToVideoInputs, TextEncodeHunyuanVideo_ImageToVideoOutputs]):
    """
    Original name: TextEncodeHunyuanVideo_ImageToVideo
    No description available.
    """
    _original_name: str = 'TextEncodeHunyuanVideo_ImageToVideo'

    def __init__(self, clip: Slot[Clip], clip_vision_output: Slot[Any], prompt: str, image_interleave: int = 2):
        super().__init__(**{"clip": clip, "clip_vision_output": clip_vision_output, "prompt": prompt, "image_interleave": image_interleave})
        self.inputs = TextEncodeHunyuanVideo_ImageToVideoInputs(self)
        self.outputs = TextEncodeHunyuanVideo_ImageToVideoOutputs(self)
