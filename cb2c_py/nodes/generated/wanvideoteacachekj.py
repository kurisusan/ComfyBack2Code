
# This file is auto-generated by generate_nodes.py
# Do not edit this file directly.

from ..base_node import Node, InputSlots, OutputSlots, Slot, Model, Conditioning, Latent, Image, Vae, Clip
from typing import Dict, Any, List, Union

# Define input and output slot classes for WanVideoTeaCacheKJ
class WanVideoTeaCacheKJInputs(InputSlots):
    model: Slot[Model]
    rel_l1_thresh: Slot[float]
    start_percent: Slot[float]
    end_percent: Slot[float]
    cache_device: Slot[str]
    coefficients: Slot[str]
    def __init__(self, node: "Node"):
        self.model = Slot[Model](node, "model", 'MODEL')
        self.rel_l1_thresh = Slot[float](node, "rel_l1_thresh", 'FLOAT')
        self.start_percent = Slot[float](node, "start_percent", 'FLOAT')
        self.end_percent = Slot[float](node, "end_percent", 'FLOAT')
        self.cache_device = Slot[str](node, "cache_device", ['main_device', 'offload_device'])
        self.coefficients = Slot[str](node, "coefficients", ['disabled', '1.3B', '14B', 'i2v_480', 'i2v_720'])

class WanVideoTeaCacheKJOutputs(OutputSlots):
    model: Slot[Model]
    def __init__(self, node: "Node"):
        self.model = Slot[Model](node, "model", 'MODEL')

class WanVideoTeaCacheKJ(Node[WanVideoTeaCacheKJInputs, WanVideoTeaCacheKJOutputs]):
    """
    Original name: WanVideoTeaCacheKJ
    Category: KJNodes/teacache
    
Patch WanVideo model to use TeaCache. Speeds up inference by caching the output and  
applying it instead of doing the step.  Best results are achieved by choosing the  
appropriate coefficients for the model. Early steps should never be skipped, with too  
aggressive values this can happen and the motion suffers. Starting later can help with that too.   
When NOT using coefficients, the threshold value should be  
about 10 times smaller than the value used with coefficients.  

Official recommended values https://github.com/ali-vilab/TeaCache/tree/main/TeaCache4Wan2.1:


<pre style='font-family:monospace'>
+-------------------+--------+---------+--------+
|       Model       |  Low   | Medium  |  High  |
+-------------------+--------+---------+--------+
| Wan2.1 t2v 1.3B  |  0.05  |  0.07   |  0.08  |
| Wan2.1 t2v 14B   |  0.14  |  0.15   |  0.20  |
| Wan2.1 i2v 480P  |  0.13  |  0.19   |  0.26  |
| Wan2.1 i2v 720P  |  0.18  |  0.20   |  0.30  |
+-------------------+--------+---------+--------+
</pre> 


    Inputs:
        - model (Model)
        - rel_l1_thresh (float) (default: 0.275)
          Threshold for to determine when to apply the cache, compromise between speed and accuracy. When using coefficients a good value range is something between 0.2-0.4 for all but 1.3B model, which should be about 10 times smaller, same as when not using coefficients.
        - start_percent (float) (default: 0.1)
          The start percentage of the steps to use with TeaCache.
        - end_percent (float) (default: 1.0)
          The end percentage of the steps to use with TeaCache.
        - cache_device (str) (default: 'offload_device')
          Device to cache to
        - coefficients (str) (default: 'i2v_480')
          Coefficients for rescaling the relative l1 distance, if disabled the threshold value should be about 10 times smaller than the value used with coefficients.

    Outputs:
        - model (Model)
    """
    _original_name: str = 'WanVideoTeaCacheKJ'

    def __init__(self, model: Slot[Model], rel_l1_thresh: float = 0.275, start_percent: float = 0.1, end_percent: float = 1.0, cache_device: str = 'offload_device', coefficients: str = 'i2v_480'):
        super().__init__(**{"model": model, "rel_l1_thresh": rel_l1_thresh, "start_percent": start_percent, "end_percent": end_percent, "cache_device": cache_device, "coefficients": coefficients})
        self.inputs = WanVideoTeaCacheKJInputs(self)
        self.outputs = WanVideoTeaCacheKJOutputs(self)
