
# This file is auto-generated by generate_nodes.py
# Do not edit this file directly.

from ..base_node import Node, InputSlots, OutputSlots, Slot, Model, Conditioning, Latent, Image, Vae, Clip
from typing import Dict, Any, List, Union

# Define input and output slot classes for SVD_img2vid_Conditioning
class SVD_img2vid_ConditioningInputs(InputSlots):
    clip_vision: Slot[Any]
    init_image: Slot[Image]
    vae: Slot[Vae]
    width: Slot[int]
    height: Slot[int]
    video_frames: Slot[int]
    motion_bucket_id: Slot[int]
    fps: Slot[int]
    augmentation_level: Slot[float]
    def __init__(self, node: "Node"):
        self.clip_vision = Slot[Any](node, "clip_vision", 'CLIP_VISION')
        self.init_image = Slot[Image](node, "init_image", 'IMAGE')
        self.vae = Slot[Vae](node, "vae", 'VAE')
        self.width = Slot[int](node, "width", 'INT')
        self.height = Slot[int](node, "height", 'INT')
        self.video_frames = Slot[int](node, "video_frames", 'INT')
        self.motion_bucket_id = Slot[int](node, "motion_bucket_id", 'INT')
        self.fps = Slot[int](node, "fps", 'INT')
        self.augmentation_level = Slot[float](node, "augmentation_level", 'FLOAT')

class SVD_img2vid_ConditioningOutputs(OutputSlots):
    positive: Slot[Conditioning]
    negative: Slot[Conditioning]
    latent: Slot[Latent]
    def __init__(self, node: "Node"):
        self.positive = Slot[Conditioning](node, "positive", 'CONDITIONING')
        self.negative = Slot[Conditioning](node, "negative", 'CONDITIONING')
        self.latent = Slot[Latent](node, "latent", 'LATENT')

class SVD_img2vid_Conditioning(Node[SVD_img2vid_ConditioningInputs, SVD_img2vid_ConditioningOutputs]):
    """
    Original name: SVD_img2vid_Conditioning
    No description available.
    """
    _original_name: str = 'SVD_img2vid_Conditioning'

    def __init__(self, clip_vision: Slot[Any], init_image: Slot[Image], vae: Slot[Vae], width: int = 1024, height: int = 576, video_frames: int = 14, motion_bucket_id: int = 127, fps: int = 6, augmentation_level: float = 0.0):
        super().__init__(**{"clip_vision": clip_vision, "init_image": init_image, "vae": vae, "width": width, "height": height, "video_frames": video_frames, "motion_bucket_id": motion_bucket_id, "fps": fps, "augmentation_level": augmentation_level})
        self.inputs = SVD_img2vid_ConditioningInputs(self)
        self.outputs = SVD_img2vid_ConditioningOutputs(self)
