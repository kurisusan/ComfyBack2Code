
# This file is auto-generated by generate_nodes.py
# Do not edit this file directly.

from ..base_node import Node

class OpenAIChatConfig(Node):
    """
    Original name: OpenAIChatConfig
    No description available.
    """
    _inputs = {
    "truncation": [
        "COMBO",
        {
            "options": [
                "auto",
                "disabled"
            ],
            "default": "auto",
            "tooltip": "The truncation strategy to use for the model response. auto: If the context of this response and previous ones exceeds the model's context window size, the model will truncate the response to fit the context window by dropping input items in the middle of the conversation.disabled: If a model response will exceed the context window size for a model, the request will fail with a 400 error"
        }
    ]
}
    _outputs = [
    "OPENAI_CHAT_CONFIG"
]
    _original_name = "OpenAIChatConfig"

    def __init__(self, truncation="auto"):
        super().__init__(truncation=truncation)

    @classmethod
    def get_inputs(cls):
        return cls._inputs

    @classmethod
    def get_outputs(cls):
        return cls._outputs
