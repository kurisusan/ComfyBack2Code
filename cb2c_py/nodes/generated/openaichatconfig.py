
# This file is auto-generated by generate_nodes.py
# Do not edit this file directly.

from ..base_node import Node, InputSlots, OutputSlots, Slot, Model, Conditioning, Latent, Image, Vae, Clip
from typing import Dict, Any, List, Union

# Define input and output slot classes for OpenAIChatConfig
class OpenAIChatConfigInputs(InputSlots):
    truncation: Slot[str]
    def __init__(self, node: "Node"):
        self.truncation = Slot[str](node, "truncation", 'COMBO')

class OpenAIChatConfigOutputs(OutputSlots):
    openai_chat_config: Slot[Any]
    def __init__(self, node: "Node"):
        self.openai_chat_config = Slot[Any](node, "OPENAI_CHAT_CONFIG", 'OPENAI_CHAT_CONFIG')

class OpenAIChatConfig(Node[OpenAIChatConfigInputs, OpenAIChatConfigOutputs]):
    """
    Original name: OpenAIChatConfig
    Category: api node/text/OpenAI
    Allows specifying advanced configuration options for the OpenAI Chat Nodes.

    Inputs:
        - truncation (Any) (default: 'auto')
          The truncation strategy to use for the model response. auto: If the context of this response and previous ones exceeds the model's context window size, the model will truncate the response to fit the context window by dropping input items in the middle of the conversation.disabled: If a model response will exceed the context window size for a model, the request will fail with a 400 error

    Outputs:
        - openai_chat_config (Any)
    """
    _original_name: str = 'OpenAIChatConfig'

    def __init__(self, truncation: str = 'auto'):
        super().__init__(**{"truncation": truncation})
        self.inputs = OpenAIChatConfigInputs(self)
        self.outputs = OpenAIChatConfigOutputs(self)
