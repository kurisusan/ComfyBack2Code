
# This file is auto-generated by generate_nodes.py
# Do not edit this file directly.

from ..base_node import Node

class DiffusionModelLoaderKJ(Node):
    """
    Original name: DiffusionModelLoaderKJ
    No description available.
    """
    _inputs = {
    "model_name": [
        [
            "Wan2_1-VACE_module_14B_fp8_e4m3fn.safetensors",
            "Wan2_1_VACE_1_3B_preview_bf16.safetensors",
            "cosmos_predict2_2B_video2world_480p_16fps.safetensors",
            "omnigen2_fp16.safetensors",
            "svdq-fp4_r32-flux.1-kontext-dev.safetensors",
            "wan2.1_vace_1.3B_fp16.safetensors",
            "wan2.1_vace_14B_fp8_e4m3fn.safetensors"
        ],
        {
            "tooltip": "The name of the checkpoint (model) to load."
        }
    ],
    "weight_dtype": [
        [
            "default",
            "fp8_e4m3fn",
            "fp8_e4m3fn_fast",
            "fp8_e5m2",
            "fp16",
            "bf16",
            "fp32"
        ]
    ],
    "compute_dtype": [
        [
            "default",
            "fp16",
            "bf16",
            "fp32"
        ],
        {
            "default": "default",
            "tooltip": "The compute dtype to use for the model."
        }
    ],
    "patch_cublaslinear": [
        "BOOLEAN",
        {
            "default": False,
            "tooltip": "Enable or disable the patching, won't take effect on already loaded models!"
        }
    ],
    "sage_attention": [
        [
            "disabled",
            "auto",
            "sageattn_qk_int8_pv_fp16_cuda",
            "sageattn_qk_int8_pv_fp16_triton",
            "sageattn_qk_int8_pv_fp8_cuda",
            "sageattn_qk_int8_pv_fp8_cuda++"
        ],
        {
            "default": False,
            "tooltip": "Patch comfy attention to use sageattn."
        }
    ],
    "enable_fp16_accumulation": [
        "BOOLEAN",
        {
            "default": False,
            "tooltip": "Enable torch.backends.cuda.matmul.allow_fp16_accumulation, requires pytorch 2.7.0 nightly."
        }
    ]
}
    _outputs = [
    "MODEL"
]
    _original_name = "DiffusionModelLoaderKJ"

    def __init__(self, model_name, weight_dtype, compute_dtype="default", patch_cublaslinear=False, sage_attention=False, enable_fp16_accumulation=False):
        super().__init__(model_name=model_name, weight_dtype=weight_dtype, compute_dtype=compute_dtype, patch_cublaslinear=patch_cublaslinear, sage_attention=sage_attention, enable_fp16_accumulation=enable_fp16_accumulation)

    @classmethod
    def get_inputs(cls):
        return cls._inputs

    @classmethod
    def get_outputs(cls):
        return cls._outputs
