
# This file is auto-generated by generate_nodes.py
# Do not edit this file directly.

from ..base_node import Node, InputSlots, OutputSlots, Slot, Model, Conditioning, Latent, Image, Vae, Clip
from typing import Dict, Any, List, Union

# Define input and output slot classes for DiffusionModelLoaderKJ
class DiffusionModelLoaderKJInputs(InputSlots):
    model_name: Slot[str]
    weight_dtype: Slot[str]
    compute_dtype: Slot[str]
    patch_cublaslinear: Slot[bool]
    sage_attention: Slot[str]
    enable_fp16_accumulation: Slot[bool]
    def __init__(self, node: "Node"):
        self.model_name = Slot[str](node, "model_name", [])
        self.weight_dtype = Slot[str](node, "weight_dtype", ['default', 'fp8_e4m3fn', 'fp8_e4m3fn_fast', 'fp8_e5m2', 'fp16', 'bf16', 'fp32'])
        self.compute_dtype = Slot[str](node, "compute_dtype", ['default', 'fp16', 'bf16', 'fp32'])
        self.patch_cublaslinear = Slot[bool](node, "patch_cublaslinear", 'BOOLEAN')
        self.sage_attention = Slot[str](node, "sage_attention", ['disabled', 'auto', 'sageattn_qk_int8_pv_fp16_cuda', 'sageattn_qk_int8_pv_fp16_triton', 'sageattn_qk_int8_pv_fp8_cuda', 'sageattn_qk_int8_pv_fp8_cuda++'])
        self.enable_fp16_accumulation = Slot[bool](node, "enable_fp16_accumulation", 'BOOLEAN')

class DiffusionModelLoaderKJOutputs(OutputSlots):
    model: Slot[Model]
    def __init__(self, node: "Node"):
        self.model = Slot[Model](node, "MODEL", 'MODEL')

class DiffusionModelLoaderKJ(Node[DiffusionModelLoaderKJInputs, DiffusionModelLoaderKJOutputs]):
    """
    Original name: DiffusionModelLoaderKJ
    No description available.
    """
    _original_name: str = 'DiffusionModelLoaderKJ'

    def __init__(self, model_name: str, weight_dtype: str, compute_dtype: str = 'default', patch_cublaslinear: bool = False, sage_attention: str = 'False', enable_fp16_accumulation: bool = False):
        super().__init__(**{"model_name": model_name, "weight_dtype": weight_dtype, "compute_dtype": compute_dtype, "patch_cublaslinear": patch_cublaslinear, "sage_attention": sage_attention, "enable_fp16_accumulation": enable_fp16_accumulation})
        self.inputs = DiffusionModelLoaderKJInputs(self)
        self.outputs = DiffusionModelLoaderKJOutputs(self)
