
# This file is auto-generated by generate_nodes.py
# Do not edit this file directly.

from ..base_node import Node, InputSlots, OutputSlots, Slot, Model, Conditioning, Latent, Image, Vae, Clip
from typing import Dict, Any, List, Union

# Define input and output slot classes for GLIGENTextBoxApplyBatchCoords
class GLIGENTextBoxApplyBatchCoordsInputs(InputSlots):
    conditioning_to: Slot[Conditioning]
    latents: Slot[Latent]
    clip: Slot[Clip]
    gligen_textbox_model: Slot[Any]
    coordinates: Slot[str]
    text: Slot[str]
    width: Slot[int]
    height: Slot[int]
    def __init__(self, node: "Node"):
        self.conditioning_to = Slot[Conditioning](node, "conditioning_to", 'CONDITIONING')
        self.latents = Slot[Latent](node, "latents", 'LATENT')
        self.clip = Slot[Clip](node, "clip", 'CLIP')
        self.gligen_textbox_model = Slot[Any](node, "gligen_textbox_model", 'GLIGEN')
        self.coordinates = Slot[str](node, "coordinates", 'STRING')
        self.text = Slot[str](node, "text", 'STRING')
        self.width = Slot[int](node, "width", 'INT')
        self.height = Slot[int](node, "height", 'INT')

class GLIGENTextBoxApplyBatchCoordsOutputs(OutputSlots):
    conditioning: Slot[Conditioning]
    coord_preview: Slot[Image]
    def __init__(self, node: "Node"):
        self.conditioning = Slot[Conditioning](node, "conditioning", 'CONDITIONING')
        self.coord_preview = Slot[Image](node, "coord_preview", 'IMAGE')

class GLIGENTextBoxApplyBatchCoords(Node[GLIGENTextBoxApplyBatchCoordsInputs, GLIGENTextBoxApplyBatchCoordsOutputs]):
    """
    Original name: GLIGENTextBoxApplyBatchCoords
    Category: KJNodes/experimental
    
This node allows scheduling GLIGEN text box positions in a batch,  
to be used with AnimateDiff-Evolved. Intended to pair with the  
Spline Editor -node.  

GLIGEN model can be downloaded through the Manage's "Install Models" menu.  
Or directly from here:  
https://huggingface.co/comfyanonymous/GLIGEN_pruned_safetensors/tree/main  
  
Inputs:  
- **latents** input is used to calculate batch size  
- **clip** is your standard text encoder, use same as for the main prompt  
- **gligen_textbox_model** connects to GLIGEN Loader  
- **coordinates** takes a json string of points, directly compatible  
with the spline editor node.
- **text** is the part of the prompt to set position for  
- **width** and **height** are the size of the GLIGEN bounding box  
  
Outputs:
- **conditioning** goes between to clip text encode and the sampler  
- **coord_preview** is an optional preview of the coordinates and  
bounding boxes.



    Inputs:
        - conditioning_to (Conditioning)
        - latents (Latent)
        - clip (Clip)
        - gligen_textbox_model (Any)
        - coordinates (str)
        - text (str)
        - width (int) (default: 128)
        - height (int) (default: 128)

    Outputs:
        - conditioning (Conditioning)
        - coord_preview (Image)
    """
    _original_name: str = 'GLIGENTextBoxApplyBatchCoords'

    def __init__(self, conditioning_to: Slot[Conditioning], latents: Slot[Latent], clip: Slot[Clip], gligen_textbox_model: Slot[Any], coordinates: str, text: str, width: int = 128, height: int = 128):
        super().__init__(**{"conditioning_to": conditioning_to, "latents": latents, "clip": clip, "gligen_textbox_model": gligen_textbox_model, "coordinates": coordinates, "text": text, "width": width, "height": height})
        self.inputs = GLIGENTextBoxApplyBatchCoordsInputs(self)
        self.outputs = GLIGENTextBoxApplyBatchCoordsOutputs(self)
