
# This file is auto-generated by generate_nodes.py
# Do not edit this file directly.

from ..base_node import Node, InputSlots, OutputSlots, Slot, Model, Conditioning, Latent, Image, Vae, Clip
from typing import Dict, Any, List, Union

# Define input and output slot classes for TorchCompileCosmosModel
class TorchCompileCosmosModelInputs(InputSlots):
    model: Slot[Model]
    backend: Slot[str]
    fullgraph: Slot[bool]
    mode: Slot[str]
    dynamic: Slot[bool]
    dynamo_cache_size_limit: Slot[int]
    def __init__(self, node: "Node"):
        self.model = Slot[Model](node, "model", 'MODEL')
        self.backend = Slot[str](node, "backend", ['inductor', 'cudagraphs'])
        self.fullgraph = Slot[bool](node, "fullgraph", 'BOOLEAN')
        self.mode = Slot[str](node, "mode", ['default', 'max-autotune', 'max-autotune-no-cudagraphs', 'reduce-overhead'])
        self.dynamic = Slot[bool](node, "dynamic", 'BOOLEAN')
        self.dynamo_cache_size_limit = Slot[int](node, "dynamo_cache_size_limit", 'INT')

class TorchCompileCosmosModelOutputs(OutputSlots):
    model: Slot[Model]
    def __init__(self, node: "Node"):
        self.model = Slot[Model](node, "MODEL", 'MODEL')

class TorchCompileCosmosModel(Node[TorchCompileCosmosModelInputs, TorchCompileCosmosModelOutputs]):
    """
    Original name: TorchCompileCosmosModel
    No description available.
    """
    _original_name: str = 'TorchCompileCosmosModel'

    def __init__(self, model: Slot[Model], backend: str, fullgraph: bool = False, mode: str = 'default', dynamic: bool = False, dynamo_cache_size_limit: int = 64):
        super().__init__(**{"model": model, "backend": backend, "fullgraph": fullgraph, "mode": mode, "dynamic": dynamic, "dynamo_cache_size_limit": dynamo_cache_size_limit})
        self.inputs = TorchCompileCosmosModelInputs(self)
        self.outputs = TorchCompileCosmosModelOutputs(self)
